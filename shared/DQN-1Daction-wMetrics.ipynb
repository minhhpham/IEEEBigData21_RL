{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Implementation of DQN.\n",
    "#     State: (Click History, User Portraits) (note: purchase timestamp is not available in testset)\n",
    "#     Action: itemID (each sample is split into 9 steps)\n",
    "#     Rewards: Total price of purchased items\n",
    "# 0. split train data into training set and validation set\n",
    "# 1. prepare data for DQN from training set\n",
    "# 2. prepare data for DQN from validation set\n",
    "# 3. train DQN\n",
    "# 4. make suggestions for validation set\n",
    "# 5. Calculate Metrics 1 for our suggestions\n",
    "# 6. Generate suggestions for provided testset for true scoring\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Multiprocessing threads: 31\n"
     ]
    }
   ],
   "source": [
    "# 0. Split Train into training set and validation set\n",
    "from DataPrep import *\n",
    "from tqdm import tqdm\n",
    "userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
    "# when training, userFeaturesTrain represent state\n",
    "N_ITEMS = 381\n",
    "# load item price\n",
    "itemInfo = pd.read_csv('/tf/shared/item_info.csv', ' ')\n",
    "itemInfo = itemInfo.sort_values(by = 'item_id')\n",
    "itemPrice = itemInfo.price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minh/anaconda3/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator KMeans from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/minh/anaconda3/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator SparsePCA from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dimension reduction with PCA\n",
    "# comment this part out to use original user features \n",
    "import pandas as pd\n",
    "\n",
    "# cluster model of 20D\n",
    "from DataPrep import getClusterModel200_20D\n",
    "ClusterModel, clusterLabels = getClusterModel200_20D()\n",
    "\n",
    "from DataPrep import getPCATransformer\n",
    "PCAtransformer = getPCATransformer()\n",
    "userFeaturesTrain = pd.DataFrame(PCAtransformer.transform(userFeaturesTrain))\n",
    "userFeaturesVal = pd.DataFrame(PCAtransformer.transform(userFeaturesVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 208069/208069 [00:37<00:00, 5484.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. prepare data for training set\n",
    "import numpy as np\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "\n",
    "statesTrain = []\n",
    "actionsTrain = []\n",
    "rewardsTrain = []\n",
    "terminalTrain = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        statesTrain.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsTrain.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsTrain.append(itemPrice[itemID-1]) # itemID-1 becuase itemPrice is a 0-based array\n",
    "        else:\n",
    "            rewardsTrain.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        else:\n",
    "            terminalTrain.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesTrain = np.array(statesTrain)\n",
    "actionsTrain = np.array(actionsTrain)\n",
    "rewardsTrain = np.array(rewardsTrain)\n",
    "terminalTrain = np.array(terminalTrain)\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 52018/52018 [00:09<00:00, 5494.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2. prepare data for validation set\n",
    "statesVal = []\n",
    "actionsVal = []\n",
    "rewardsVal = []\n",
    "terminalVal = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesVal.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesVal.iloc[i])\n",
    "    itemList = recItemsVal[i]\n",
    "    purchase = purchaseLabelVal[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to val set\n",
    "        # append step to state\n",
    "        statesVal.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsVal.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsVal.append(itemPrice[itemID-1]) # itemID-1 becuase itemPrice is a 0-based array\n",
    "        else:\n",
    "            rewardsVal.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalVal.append(0) # game continue\n",
    "        else:\n",
    "            terminalVal.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesVal = np.array(statesVal)\n",
    "actionsVal = np.array(actionsVal)\n",
    "rewardsVal = np.array(rewardsVal)\n",
    "terminalVal = np.array(terminalVal)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures.pkl', 'wb') as file:\n",
    "    pickle.dump((statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures.pkl', 'rb') as file:\n",
    "    statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal = pickle.load(file)\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import d3rlpy_wrapper\n",
    "from importlib import reload\n",
    "d3rlpy_wrapper = reload(d3rlpy_wrapper)\n",
    "\n",
    "wrapper = d3rlpy_wrapper.RLModelWrapper(datasetTrain)\n",
    "wrapper.trainAllModels(n_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models to checkpoints\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/models-3D-20DFeatures.pkl', 'wb') as file:\n",
    "    pickle.dump((wrapper.DQN, wrapper.DoubleDQN, wrapper.DiscreteBCQ, wrapper.DiscreteCQL),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "from classes import d3rlpy_wrapper\n",
    "wrapper = d3rlpy_wrapper.RLModelWrapper(datasetTrain, datasetVal)\n",
    "with open('/tf/shared/checkpoints/models-3D-20DFeatures.pkl', 'rb') as file:\n",
    "    wrapper.DQN, wrapper.DoubleDQN, wrapper.DiscreteBCQ, wrapper.DiscreteCQL = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Now we prepare test set to make prediction\n",
    "userIDs, userFeaturesTest = getUserFeaturesTestSet()\n",
    "statesTest = []  # this will be userFeaturesTest appended with a column of step = 0 to 8\n",
    "for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTest.iloc[i])\n",
    "    for step in range(9):\n",
    "        # append step to state\n",
    "        statesTest.append(state + [step])\n",
    "\n",
    "print(len(statesTest))\n",
    "statesTest = np.array(statesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate values for each item ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 381/381 [1:48:58<00:00, 17.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each sample, find best 9 items ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 797452/1854864 [03:47<03:54, 4514.93it/s] IOStream.flush timed out\n",
      "100% 1854864/1854864 [08:21<00:00, 3697.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate values for each item ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 381/381 [1:43:01<00:00, 16.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each sample, find best 9 items ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1854864/1854864 [08:15<00:00, 3741.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate values for each item ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 381/381 [1:42:41<00:00, 16.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each sample, find best 9 items ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1854864/1854864 [07:37<00:00, 4058.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate values for each item ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 381/381 [1:42:14<00:00, 16.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each sample, find best 9 items ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1854864/1854864 [08:07<00:00, 3807.36it/s] \n"
     ]
    }
   ],
   "source": [
    "# generate prediction for this expanded test sets, number of rows = nrows(test set) * 9\n",
    "itemSetDQN, itemSetDoubleDQN, itemSetDiscreteBCQ, itemSetDiscreteCQL = wrapper.predict9ItemsAllModels(statesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatenate multiple rows of itemSet into a single set for each user sample\n",
    "# for each sample:\n",
    "#     finalSet = []\n",
    "#     for each step in sample:\n",
    "#          iterate thru recommended items and add to finalSet if that item is not already in finalSet\n",
    "def finalizeItemSetsTestSet(statesInput, itemSet):\n",
    "    output = []\n",
    "    for i in tqdm(range(statesInput.shape[0])):\n",
    "        # loop through expanded samples\n",
    "        state = list(statesInput[i])\n",
    "        step = state[len(state)-1]\n",
    "        if step==0: # init new finalItemSet\n",
    "            finalItemSet = []\n",
    "        # try to add new item to finalItemSet, based on their highest value\n",
    "        for item in itemSet[i]:\n",
    "            if item not in finalItemSet:\n",
    "                finalItemSet.append(item)\n",
    "                break\n",
    "        # export finalItemSet once reaching step 8\n",
    "        if step==8:\n",
    "            assert len(finalItemSet)==9\n",
    "            output.append(finalItemSet)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1854864/1854864 [02:13<00:00, 13852.47it/s]\n",
      "100% 1854864/1854864 [02:13<00:00, 13845.74it/s]\n",
      "100% 1854864/1854864 [02:13<00:00, 13876.70it/s]\n",
      "100% 1854864/1854864 [02:13<00:00, 13853.38it/s]\n"
     ]
    }
   ],
   "source": [
    "finalItemSetDQN = finalizeItemSetsTestSet(statesTest, itemSetDQN)\n",
    "finalItemSetDoubleDQN = finalizeItemSetsTestSet(statesTest, itemSetDoubleDQN)\n",
    "finalItemSetDiscreteBCQ = finalizeItemSetsTestSet(statesTest, itemSetDiscreteBCQ)\n",
    "finalItemSetDiscreteCQL = finalizeItemSetsTestSet(statesTest, itemSetDiscreteCQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save results to output\n",
    "# format data according to submission format and write to file\n",
    "def writeOutput(finalItemSet, outFileName, userIDs_ = userIDs, outDir = '/tf/shared/outputs/'):\n",
    "    outFile = outDir + outFileName\n",
    "    f = open(outFile, \"w\")\n",
    "    f.write('id,itemids')\n",
    "    for i in range(len(userIDs_)):\n",
    "        f.write('\\n')\n",
    "        itemList = finalItemSet[i]\n",
    "        itemString = ' '.join([str(j) for j in itemList])\n",
    "        outString = str(userIDs_[i]) + ',' + itemString\n",
    "        f.write(outString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutput(finalItemSetDQN, 'DQN_20DFeatures.csv')\n",
    "writeOutput(finalItemSetDoubleDQN, 'DoubleDQN_20DFeatures.csv')\n",
    "writeOutput(finalItemSetDiscreteBCQ, 'DiscreteBCQ_20DFeatures.csv')\n",
    "writeOutput(finalItemSetDiscreteCQL, 'DiscreteCQL_20DFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate values for each item ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [12:33<00:00,  1.98s/it]\n",
      "  0%|          | 0/354819 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each sample, find best 9 items ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354819/354819 [00:42<00:00, 8328.96it/s]\n",
      "  0%|          | 0/354819 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bfd8cd923e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinalItemSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mfinalItemSetDQN_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalizeItemSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatesVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemSetDQN_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mfinalItemSetDoubleDQN_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalizeItemSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatesVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemSetDoubleDQN_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mfinalItemSetDiscreteBCQ_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalizeItemSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatesVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemSetDiscreteBCQ_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bfd8cd923e32>\u001b[0m in \u001b[0;36mfinalizeItemSets\u001b[0;34m(statesInput, itemSet)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mfinalItemSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinalItemSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "####################### Now we calculate our Metrics1 on the 4 models ##################################\n",
    "from classes.Metrics import Metrics\n",
    "metrics = Metrics(recItemsVal, purchaseLabelVal)\n",
    "\n",
    "################### generate prediction for expanded val set\n",
    "itemSetDQN_val, itemSetDoubleDQN_val, itemSetDiscreteBCQ_val, itemSetDiscreteCQL_val = wrapper.predict9ItemsAllModels(statesVal)\n",
    "\n",
    "# function to concatenate multiple rows of val itemSet into a single set for each user sample\n",
    "# because of the way we organize data, each sample is divided into multiple rows\n",
    "def finalizeItemSets(statesInput, itemSet):\n",
    "    \"\"\" statesInput: input for models to generate itemSet \"\"\"\n",
    "    finalItemSet = []\n",
    "    for i in tqdm(range(statesInput.shape[0])):\n",
    "    # loop thru multiple rows of samples\n",
    "        # get step of the game in this row (step is range from 0 to 8), step is the last column\n",
    "        # we only get itemset from the first step = 0\n",
    "        state = list(statesInput[i])\n",
    "        step = state[len(state)-1]\n",
    "        if step==0:\n",
    "            finalItemSet.append(itemSet[i])\n",
    "    return finalItemSet\n",
    "\n",
    "finalItemSetDQN_val = finalizeItemSets(statesVal, itemSetDQN_val)\n",
    "finalItemSetDoubleDQN_val = finalizeItemSets(statesVal, itemSetDoubleDQN_val)\n",
    "finalItemSetDiscreteBCQ_val = finalizeItemSets(statesVal, itemSetDiscreteBCQ_val)\n",
    "finalItemSetDiscreteCQL_val = finalizeItemSets(statesVal, itemSetDiscreteCQL_val)\n",
    "assert len(finalItemSetDQN_val) == userFeaturesVal.shape[0]\n",
    "assert len(finalItemSetDoubleDQN_val) == userFeaturesVal.shape[0]\n",
    "assert len(finalItemSetDiscreteBCQ_val) == userFeaturesVal.shape[0]\n",
    "assert len(finalItemSetDiscreteCQL_val) == userFeaturesVal.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1_DQN = metrics.calculate_metrics2(finalItemSetDQN_val)\n",
    "metrics1_DoubleDQN = metrics.calculate_metrics2(finalItemSetDoubleDQN_val)\n",
    "metrics1_DiscreteBCQ = metrics.calculate_metrics2(finalItemSetDiscreteBCQ_val)\n",
    "metrics1_DiscreteCQL = metrics.calculate_metrics2(finalItemSetDiscreteCQL_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics1_DQN)\n",
    "print(metrics1_DoubleDQN)\n",
    "print(metrics1_DiscreteBCQ)\n",
    "print(metrics1_DiscreteCQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
