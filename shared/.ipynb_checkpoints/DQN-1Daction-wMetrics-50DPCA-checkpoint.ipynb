{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Implementation of DQN.\n",
    "#     State: (Click History, User Portraits) (note: purchase timestamp is not available in testset)\n",
    "#     Action: itemID (each sample is split into 9 steps)\n",
    "#     Rewards: Total price of purchased items\n",
    "# 0. split train data into training set and validation set\n",
    "# 1. prepare data for DQN from training set\n",
    "# 2. prepare data for DQN from validation set\n",
    "# 3. train DQN\n",
    "# 4. make suggestions for validation set\n",
    "# 5. Calculate Metrics 1 for our suggestions\n",
    "# 6. Generate suggestions for provided testset for true scoring\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Multiprocessing threads: 31\n"
     ]
    }
   ],
   "source": [
    "# 0. Split Train into training set and validation set\n",
    "from DataPrep import *\n",
    "from tqdm import tqdm\n",
    "userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
    "# when training, userFeaturesTrain represent state\n",
    "N_ITEMS = 381\n",
    "# load item price\n",
    "itemInfo = pd.read_csv('/tf/shared/item_info.csv', ' ')\n",
    "itemInfo = itemInfo.sort_values(by = 'item_id')\n",
    "itemPrice = itemInfo.price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction with PCA\n",
    "# comment this part out to use original user features \n",
    "import pandas as pd\n",
    "\n",
    "from DataPrep import getPCATransformer50\n",
    "PCAtransformer = getPCATransformer50()\n",
    "userFeaturesTrain = pd.DataFrame(PCAtransformer.transform(userFeaturesTrain))\n",
    "userFeaturesVal = pd.DataFrame(PCAtransformer.transform(userFeaturesVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208069/208069 [00:28<00:00, 7239.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. prepare data for training set\n",
    "import numpy as np\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "\n",
    "statesTrain = []\n",
    "actionsTrain = []\n",
    "rewardsTrain = []\n",
    "terminalTrain = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        statesTrain.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsTrain.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsTrain.append(itemPrice[itemID-1]) # itemID-1 becuase itemPrice is a 0-based array\n",
    "        else:\n",
    "            rewardsTrain.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        else:\n",
    "            terminalTrain.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesTrain = np.array(statesTrain)\n",
    "actionsTrain = np.array(actionsTrain)\n",
    "rewardsTrain = np.array(rewardsTrain)\n",
    "terminalTrain = np.array(terminalTrain)\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 45594/52018 [00:05<00:00, 7663.70it/s]"
     ]
    }
   ],
   "source": [
    "# 2. prepare data for validation set\n",
    "statesVal = []\n",
    "actionsVal = []\n",
    "rewardsVal = []\n",
    "terminalVal = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesVal.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesVal.iloc[i])\n",
    "    itemList = recItemsVal[i]\n",
    "    purchase = purchaseLabelVal[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to val set\n",
    "        # append step to state\n",
    "        statesVal.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsVal.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsVal.append(itemPrice[itemID-1]) # itemID-1 becuase itemPrice is a 0-based array\n",
    "        else:\n",
    "            rewardsVal.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalVal.append(0) # game continue\n",
    "        else:\n",
    "            terminalVal.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesVal = np.array(statesVal)\n",
    "actionsVal = np.array(actionsVal)\n",
    "rewardsVal = np.array(rewardsVal)\n",
    "terminalVal = np.array(terminalVal)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-50DFeatures.pkl', 'wb') as file:\n",
    "    pickle.dump((statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-50DFeatures.pkl', 'rb') as file:\n",
    "    statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal = pickle.load(file)\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import d3rlpy_wrapper\n",
    "from importlib import reload\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "d3rlpy_wrapper = reload(d3rlpy_wrapper)\n",
    "\n",
    "wrapper = d3rlpy_wrapper.RLModelWrapper(datasetTrain)\n",
    "wrapper.trainAllModels(n_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models to checkpoints\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/models-3D-50DFeatures.pkl', 'wb') as file:\n",
    "    pickle.dump((wrapper.DQN, wrapper.DoubleDQN, wrapper.DiscreteBCQ, wrapper.DiscreteCQL),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "from classes import d3rlpy_wrapper\n",
    "wrapper = d3rlpy_wrapper.RLModelWrapper(datasetTrain, datasetVal)\n",
    "with open('/tf/shared/checkpoints/models-3D-50DFeatures.pkl', 'rb') as file:\n",
    "    wrapper.DQN, wrapper.DoubleDQN, wrapper.DiscreteBCQ, wrapper.DiscreteCQL = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Now we prepare test set to make prediction\n",
    "userIDs, userFeaturesTest = getUserFeaturesTestSet()\n",
    "statesTest = []  # this will be userFeaturesTest appended with a column of step = 0 to 8\n",
    "for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTest.iloc[i])\n",
    "    for step in range(9):\n",
    "        # append step to state\n",
    "        statesTest.append(state + [step])\n",
    "\n",
    "print(len(statesTest))\n",
    "statesTest = np.array(statesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prediction for this expanded test sets, number of rows = nrows(test set) * 9\n",
    "itemSetDQN, itemSetDoubleDQN, itemSetDiscreteBCQ, itemSetDiscreteCQL = wrapper.predict9ItemsAllModels(statesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatenate multiple rows of itemSet into a single set for each user sample\n",
    "# for each sample:\n",
    "#     finalSet = []\n",
    "#     for each step in sample:\n",
    "#          iterate thru recommended items and add to finalSet if that item is not already in finalSet\n",
    "def finalizeItemSetsTestSet(statesInput, itemSet):\n",
    "    output = []\n",
    "    for i in tqdm(range(statesInput.shape[0])):\n",
    "        # loop through expanded samples\n",
    "        state = list(statesInput[i])\n",
    "        step = state[len(state)-1]\n",
    "        if step==0: # init new finalItemSet\n",
    "            finalItemSet = []\n",
    "        # try to add new item to finalItemSet, based on their highest value\n",
    "        for item in itemSet[i]:\n",
    "            if item not in finalItemSet:\n",
    "                finalItemSet.append(item)\n",
    "                break\n",
    "        # export finalItemSet once reaching step 8\n",
    "        if step==8:\n",
    "            assert len(finalItemSet)==9\n",
    "            output.append(finalItemSet)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalItemSetDQN = finalizeItemSetsTestSet(statesTest, itemSetDQN)\n",
    "# finalItemSetDoubleDQN = finalizeItemSetsTestSet(statesTest, itemSetDoubleDQN)\n",
    "finalItemSetDiscreteBCQ = finalizeItemSetsTestSet(statesTest, itemSetDiscreteBCQ)\n",
    "# finalItemSetDiscreteCQL = finalizeItemSetsTestSet(statesTest, itemSetDiscreteCQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save results to output\n",
    "# format data according to submission format and write to file\n",
    "def writeOutput(finalItemSet, outFileName, userIDs_ = userIDs, outDir = '/tf/shared/outputs/'):\n",
    "    outFile = outDir + outFileName\n",
    "    f = open(outFile, \"w\")\n",
    "    f.write('id,itemids')\n",
    "    for i in range(len(userIDs_)):\n",
    "        f.write('\\n')\n",
    "        itemList = finalItemSet[i]\n",
    "        itemString = ' '.join([str(j) for j in itemList])\n",
    "        outString = str(userIDs_[i]) + ',' + itemString\n",
    "        f.write(outString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeOutput(finalItemSetDQN, 'DQN_20DFeatures.csv')\n",
    "# writeOutput(finalItemSetDoubleDQN, 'DoubleDQN_20DFeatures.csv')\n",
    "writeOutput(finalItemSetDiscreteBCQ, 'DiscreteBCQ_50DFeatures.csv')\n",
    "# writeOutput(finalItemSetDiscreteCQL, 'DiscreteCQL_20DFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################### Now we calculate our Metrics1 on the 4 models ##################################\n",
    "from classes.Metrics import Metrics\n",
    "metrics = Metrics(recItemsVal, purchaseLabelVal, itemPrice)\n",
    "\n",
    "################### generate prediction for expanded val set\n",
    "itemSetDQN_val, itemSetDoubleDQN_val, itemSetDiscreteBCQ_val, itemSetDiscreteCQL_val = wrapper.predict9ItemsAllModels(statesVal)\n",
    "\n",
    "# function to concatenate multiple rows of val itemSet into a single set for each user sample\n",
    "# because of the way we organize data, each sample is divided into multiple rows\n",
    "def finalizeItemSets(statesInput, itemSet):\n",
    "    \"\"\" statesInput: input for models to generate itemSet \"\"\"\n",
    "    finalItemSet = []\n",
    "    for i in tqdm(range(statesInput.shape[0])):\n",
    "    # loop thru multiple rows of samples\n",
    "        # get step of the game in this row (step is range from 0 to 8), step is the last column\n",
    "        # we only get itemset from the first step = 0\n",
    "        state = list(statesInput[i])\n",
    "        step = state[len(state)-1]\n",
    "        if step==0:\n",
    "            finalItemSet.append(itemSet[i])\n",
    "    return finalItemSet\n",
    "\n",
    "# finalItemSetDQN_val = finalizeItemSets(statesVal, itemSetDQN_val)\n",
    "# finalItemSetDoubleDQN_val = finalizeItemSets(statesVal, itemSetDoubleDQN_val)\n",
    "finalItemSetDiscreteBCQ_val = finalizeItemSets(statesVal, itemSetDiscreteBCQ_val)\n",
    "# finalItemSetDiscreteCQL_val = finalizeItemSets(statesVal, itemSetDiscreteCQL_val)\n",
    "# assert len(finalItemSetDQN_val) == userFeaturesVal.shape[0]\n",
    "# assert len(finalItemSetDoubleDQN_val) == userFeaturesVal.shape[0]\n",
    "assert len(finalItemSetDiscreteBCQ_val) == userFeaturesVal.shape[0]\n",
    "# assert len(finalItemSetDiscreteCQL_val) == userFeaturesVal.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics1_DQN = metrics.calculate_metrics1(finalItemSetDQN_val)\n",
    "# metrics1_DoubleDQN = metrics.calculate_metrics1(finalItemSetDoubleDQN_val)\n",
    "metrics1_DiscreteBCQ = metrics.calculate_metrics1(finalItemSetDiscreteBCQ_val)\n",
    "# metrics1_DiscreteCQL = metrics.calculate_metrics1(finalItemSetDiscreteCQL_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics1_DQN)\n",
    "# print(metrics1_DoubleDQN)\n",
    "print(metrics1_DiscreteBCQ)\n",
    "# print(metrics1_DiscreteCQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
