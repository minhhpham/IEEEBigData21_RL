{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21feb90-2a7a-4a53-80a7-22714db93437",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# BCQ to predict first 3D item set\n",
    "# Q Learning to predict the other 2 item sets \n",
    "#     Q Table: state = itemSetID\n",
    "#              action = itemSetID\n",
    "#\n",
    "# 0. split train data into training set and validation set\n",
    "# ----- Train BCQ -----------------\n",
    "# 1.1 prepare data for training set:\n",
    "#       state: 0, 1, 2\n",
    "#       action: itemSetID\n",
    "# 1.2 Train BCQ\n",
    "#\n",
    "# ----- Train Q Learning ----------\n",
    "# 2.1 prepare data for training set:\n",
    "#     state: itemSetID\n",
    "#     action itemSetID\n",
    "# 2.2 Train Q Learning\n",
    "# \n",
    "# ----- Prediction ----------------\n",
    "# 3.1 transform userFeaturesTest to 20D by using PCA\n",
    "# 3.2 Make prediction of the first itemSet by using BCQModel, name it itemSet1\n",
    "# 3.3 use itemSet1 as state for QLModel to predict best itemSet2\n",
    "# 3.4 use itemSet2 as state for QLModel to predict best itemSet3\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c265706-3767-47fa-a41c-958e0ce0b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Multiprocessing threads: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2094004/3257893058.py:3: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
      "/tmp/ipykernel_2094004/3257893058.py:10: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  itemInfo = Items()\n"
     ]
    }
   ],
   "source": [
    "# 1. Split Train \n",
    "from DataPrep import *\n",
    "userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
    "userFeaturesTrain = pd.concat((userFeaturesTrain, userFeaturesVal), ignore_index=True)\n",
    "recItemsTrain = np.vstack((recItemsTrain, recItemsVal))\n",
    "purchaseLabelTrain = np.vstack((purchaseLabelTrain, purchaseLabelVal))\n",
    "\n",
    "# load item info\n",
    "from classes.Items import Items\n",
    "itemInfo = Items()\n",
    "# translator from (ID1, ID2, ID3) to setID\n",
    "from classes.ItemSet import ItemSet3\n",
    "itemSet3 = ItemSet3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2150bddc-23e4-40a8-8759-fee6a2b3f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction with PCA\n",
    "# comment this part out to use original user features \n",
    "import pandas as pd\n",
    "\n",
    "# cluster model of 20D\n",
    "from DataPrep import getClusterModel200_20D\n",
    "ClusterModel, clusterLabels = getClusterModel200_20D()\n",
    "\n",
    "from DataPrep import getPCATransformer\n",
    "PCAtransformer = getPCATransformer()\n",
    "userFeaturesTrain = pd.DataFrame(PCAtransformer.transform(userFeaturesTrain))\n",
    "userFeaturesVal = pd.DataFrame(PCAtransformer.transform(userFeaturesVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cffb70-9303-47e5-bd38-edc0f9e189ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 prepare data for training set\n",
    "import numpy as np\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "\n",
    "statesTrain = []\n",
    "actionsTrain = []\n",
    "rewardsTrain = []\n",
    "terminalTrain = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(3):\n",
    "        # check if game is still running\n",
    "        if step>0 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>1 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        if step==0:\n",
    "            step_OneHot = [1, 0, 0]\n",
    "        elif step==1:\n",
    "            step_OneHot = [0, 1, 0]\n",
    "        else:\n",
    "            step_OneHot = [0, 0, 1]\n",
    "        statesTrain.append(state + step_OneHot)\n",
    "        # action = itemSetID\n",
    "        itemIDs = (itemList[step*3], itemList[step*3+1], itemList[step*3+2])\n",
    "        itemSetID = itemSet3.getSetID(itemIDs)\n",
    "        actionsTrain.append(itemSetID)\n",
    "        # calculate reward\n",
    "        price0 = itemInfo.getItemPrice(itemIDs[0])\n",
    "        price1 = itemInfo.getItemPrice(itemIDs[1])\n",
    "        price2 = itemInfo.getItemPrice(itemIDs[2])\n",
    "        purch0 = purchase[step*3]\n",
    "        purch1 = purchase[step*3+1]\n",
    "        purch2 = purchase[step*3+2]\n",
    "        reward = price0*purch0 + price1*purch1 + price2*purch2\n",
    "        rewardsTrain.append(reward)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step!=2:\n",
    "            if purch0*purch1*purch2 == 1: # game continue if all is 1\n",
    "                terminalTrain.append(0)\n",
    "            else:\n",
    "                terminalTrain.append(1) # game stop\n",
    "        else: # game stop at step 2\n",
    "            terminalTrain.append(1)\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesTrain = np.array(statesTrain)\n",
    "actionsTrain = np.array(actionsTrain)\n",
    "rewardsTrain = np.array(rewardsTrain)\n",
    "terminalTrain = np.array(terminalTrain)\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1ba22-d396-4102-8b5e-0aa210bea810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 prepare data for validation set\n",
    "statesVal = []\n",
    "actionsVal = []\n",
    "rewardsVal = []\n",
    "terminalVal = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(3):\n",
    "        # check if game is still running\n",
    "        if step>0 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>1 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        if step==0:\n",
    "            step_OneHot = [1, 0, 0]\n",
    "        elif step==1:\n",
    "            step_OneHot = [0, 1, 0]\n",
    "        else:\n",
    "            step_OneHot = [0, 0, 1]\n",
    "        statesVal.append(state + step_OneHot)\n",
    "        # action = itemSetID\n",
    "        itemIDs = (itemList[step*3], itemList[step*3+1], itemList[step*3+2])\n",
    "        itemSetID = itemSet3.getSetID(itemIDs)\n",
    "        actionsVal.append(itemSetID)\n",
    "        # calculate reward\n",
    "        price0 = itemInfo.getItemPrice(itemIDs[0])\n",
    "        price1 = itemInfo.getItemPrice(itemIDs[1])\n",
    "        price2 = itemInfo.getItemPrice(itemIDs[2])\n",
    "        purch0 = purchase[step*3]\n",
    "        purch1 = purchase[step*3+1]\n",
    "        purch2 = purchase[step*3+2]\n",
    "        reward = price0*purch0 + price1*purch1 + price2*purch2\n",
    "        rewardsVal.append(reward)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step!=2:\n",
    "            if purch0*purch1*purch2 == 1: # game continue if all is 1\n",
    "                terminalVal.append(0)\n",
    "            else:\n",
    "                terminalVal.append(1) # game stop\n",
    "        else: # game stop at step 2\n",
    "            terminalVal.append(1)\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesVal = np.array(statesVal)\n",
    "actionsVal = np.array(actionsVal)\n",
    "rewardsVal = np.array(rewardsVal)\n",
    "terminalVal = np.array(terminalVal)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19e43bf-75c8-45d3-b08a-1028f4d94b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures2.pkl', 'wb') as file:\n",
    "    pickle.dump((statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaa01a8-2530-46bb-ad49-936e72a08dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures2.pkl', 'rb') as file:\n",
    "    statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal = pickle.load(file)\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee377ed-9ed8-4d36-aab5-139dfa52c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-14 17:27.29 [debug    ] RoundIterator is selected.\n",
      "2021-08-14 17:27.29 [info     ] Directory is created at d3rlpy_logs/DiscreteBCQ_20210814172729\n",
      "2021-08-14 17:27.29 [warning  ] Skip building models since they're already built.\n",
      "2021-08-14 17:30.41 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_10367.pt\n",
      "2021-08-14 17:33.52 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_20734.pt\n",
      "2021-08-14 17:37.04 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_31101.pt\n",
      "2021-08-14 17:40.15 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_41468.pt\n",
      "2021-08-14 17:43.27 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_51835.pt\n",
      "2021-08-14 17:46.40 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_62202.pt\n",
      "2021-08-14 17:49.53 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_72569.pt\n",
      "2021-08-14 17:53.06 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_82936.pt\n",
      "2021-08-14 17:56.18 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_93303.pt\n",
      "2021-08-14 17:59.31 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814172729/model_103670.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.00014999016991482184,\n",
       "   'time_algorithm_update': 0.017988095348362203,\n",
       "   'loss': 4309.627051256955,\n",
       "   'time_step': 0.018239713789147925}),\n",
       " (2,\n",
       "  {'time_sample_batch': 0.00015550323446587863,\n",
       "   'time_algorithm_update': 0.017992883590075646,\n",
       "   'loss': 5272.290022718949,\n",
       "   'time_step': 0.018250689874956115}),\n",
       " (3,\n",
       "  {'time_sample_batch': 0.00016099796974062172,\n",
       "   'time_algorithm_update': 0.01803122827513901,\n",
       "   'loss': 6074.42104875578,\n",
       "   'time_step': 0.018295188643289093}),\n",
       " (4,\n",
       "  {'time_sample_batch': 0.00015679865664429405,\n",
       "   'time_algorithm_update': 0.017948152267612073,\n",
       "   'loss': 5036.206231628812,\n",
       "   'time_step': 0.018206791603152406}),\n",
       " (5,\n",
       "  {'time_sample_batch': 0.0001580870644823385,\n",
       "   'time_algorithm_update': 0.01802745506597184,\n",
       "   'loss': 4432.813232633823,\n",
       "   'time_step': 0.018287723821281434}),\n",
       " (6,\n",
       "  {'time_sample_batch': 0.00016044689556367258,\n",
       "   'time_algorithm_update': 0.018087699717560947,\n",
       "   'loss': 4539.220035947806,\n",
       "   'time_step': 0.018349928785522614}),\n",
       " (7,\n",
       "  {'time_sample_batch': 0.00015850882182025147,\n",
       "   'time_algorithm_update': 0.018062130653077407,\n",
       "   'loss': 3171.121039997615,\n",
       "   'time_step': 0.018322254200042402}),\n",
       " (8,\n",
       "  {'time_sample_batch': 0.00015855359860943933,\n",
       "   'time_algorithm_update': 0.018154629081519276,\n",
       "   'loss': 2546.70930368654,\n",
       "   'time_step': 0.018416012748982462}),\n",
       " (9,\n",
       "  {'time_sample_batch': 0.0001608362719466926,\n",
       "   'time_algorithm_update': 0.018056765694598447,\n",
       "   'loss': 2466.4576432618223,\n",
       "   'time_step': 0.01831959026855869}),\n",
       " (10,\n",
       "  {'time_sample_batch': 0.00015558639464549002,\n",
       "   'time_algorithm_update': 0.01810780123021341,\n",
       "   'loss': 2485.291022430888,\n",
       "   'time_step': 0.01836466623661177})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 Train BCQ\n",
    "from d3rlpy.algos import DiscreteBCQ\n",
    "BCQModel = DiscreteBCQ(use_gpu = True)\n",
    "BCQModel.build_with_dataset(datasetTrain)\n",
    "BCQModel.fit(datasetTrain, \n",
    "    eval_episodes = datasetVal,\n",
    "    n_epochs = 10, verbose = False, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9836e897-f972-4c7d-a1f1-1c711c21b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Train Q Learning --------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef361ac-e67d-4635-815d-554e663b7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 260087/260087 [00:53<00:00, 4879.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Prepare train data set\n",
    "#### state: =N_STATES-1 if first set, =previous recommended itemSetID otherwise\n",
    "#### action: the itemSetID recommended\n",
    "#### reward: (item is purchased) * price\n",
    "#### nextState: -1 if we are at 3rd set (game terminated), =itemSetID otherwise\n",
    "#### to feed a set of (state, action, reward, nextState) to a Q table\n",
    "from tqdm import tqdm\n",
    "from classes.ItemSet import ItemSet3\n",
    "itemSet3 = ItemSet3()\n",
    "N_ACTIONS = itemSet3.getNSets()\n",
    "N_STATES = N_ACTIONS + 1 # 1 for initial state\n",
    "\n",
    "trainSetQL = []\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    recItems = recItemsTrain[i]\n",
    "    purLabel = purchaseLabelTrain[i]\n",
    "    for j in [0, 3, 6]: # process each Set3 at once\n",
    "        if j>2 and purLabel[0]*purLabel[1]*purLabel[2]==0:\n",
    "            # don't train if game stopped\n",
    "            break\n",
    "        if j>5 and purLabel[3]*purLabel[4]*purLabel[5]==0:\n",
    "            # don't train if game stopped\n",
    "            break\n",
    "        # calculate state:\n",
    "        if j==0:\n",
    "            state = N_STATES-1\n",
    "        else:\n",
    "            state = itemSetID # previous recommened itemSet\n",
    "        # action: itemSetID\n",
    "        itemSet = [recItems[j], recItems[j+1], recItems[j+2]]\n",
    "        itemSetID = itemSet3.getSetID(itemSet)\n",
    "        action = itemSetID\n",
    "        # reward:\n",
    "        prices = [itemInfo.getItemPrice(itemSet[0]), itemInfo.getItemPrice(itemSet[1]), itemInfo.getItemPrice(itemSet[2])]\n",
    "        labels = [purLabel[j], purLabel[j+1], purLabel[j+2]]\n",
    "        reward = sum([prices[t]*labels[t] for t in range(3)])\n",
    "        # next state:\n",
    "        if j==6:\n",
    "            nextState = -1\n",
    "        else:\n",
    "            nextState = itemSetID\n",
    "        # append to train data set \n",
    "        trainSetQL.append((state, action, reward, nextState))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51d0ef-35f6-44f6-9f08-fe4f23cd7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Train QL model\n",
    "# initialize\n",
    "from classes import QLearning2\n",
    "from importlib import reload  \n",
    "QLearning2 = reload(QLearning2)\n",
    "\n",
    "print('N_ACTIONS: ' + str(N_ACTIONS) + ' N_STATES: ' + str(N_STATES))\n",
    "QLModel = QLearning2.QLearning(n_states = N_STATES, n_actions = N_ACTIONS)\n",
    "# train in parallel\n",
    "# QLModel.trainParallel(trainSetQL)\n",
    "QLModel.train(trainSetQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460a1c0-402d-4bc0-b879-dbfe4c29297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/model-BCQ-QL.pkl', 'wb') as file:\n",
    "    pickle.dump((BCQModel, QLModel),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a5f68-ca01-4cf4-9994-5590bcad2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/model-BCQ-QL.pkl.pkl', 'rb') as file:\n",
    "    BCQModel, QLModel = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426de0a2-9877-4c2c-9f13-62230110bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## PREDICTION ##########################################\n",
    "userIDs, userFeaturesTest = getUserFeaturesTestSet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3f698-b63f-40ec-ba25-e96a0dfe7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 transform userFeaturesTest to 20D by using PCA\n",
    "userFeaturesTest = pd.DataFrame(PCAtransformer.transform(userFeaturesTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504030e-172b-4417-8cab-36028c241bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QLModel.initPredCache()\n",
    "recItems_test = []\n",
    "for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# loop thru samples\n",
    "    recItems = []  # recommended list for this sample\n",
    "    # 3.2 Make prediction of the first itemSet by using BCQModel, name it itemSet1\n",
    "    state = list(userFeaturesTest.iloc[i]) + [1, 0, 0]  # first step of the game\n",
    "    itemSetID1 = BCQModel.predict([np.array(state)])[0]\n",
    "    recItems.extend(list(itemSet3.getItemSet(itemSetID1)))\n",
    "    # 3.3 use itemSet1 as state for QLModel to predict best itemSet2\n",
    "    # now stateID = itemSetID1\n",
    "    candidateSetIDs = QLModel.predictBestK(itemSetID1, 20)\n",
    "    for setID in candidateSetIDs:\n",
    "        items = itemSet3.getItemSet(setID)\n",
    "        if (items[0] not in recItems) and (items[1] not in recItems) and (items[2] not in recItems):\n",
    "            # we have found a suitable solution for step 2\n",
    "            itemSetID2 = setID\n",
    "            recItems.extend(list(items))\n",
    "            break\n",
    "    # 3.4 use itemSet2 as state for QLModel to predict best itemSet3\n",
    "    # now stateID = itemSetID2\n",
    "    candidateSetIDs = QLModel.predictBestK(itemSetID2, 20)\n",
    "    for setID in candidateSetIDs:\n",
    "        items = itemSet3.getItemSet(setID)\n",
    "        if (items[0] not in recItems) and (items[1] not in recItems) and (items[2] not in recItems):\n",
    "            # we have found a suitable solution for step 2\n",
    "            itemSetID3 = setID\n",
    "            recItems.extend(list(items))\n",
    "            break\n",
    "    recItems_test.append(recItems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f67add-ce76-457a-a2ed-97f4284b9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write recommended items to output csv file\n",
    "from classes.output import writeOutput\n",
    "writeOutput(recItems_test, 'BCQ-QLearning_v1.csv', userIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd948d1-19fc-4c28-a2f4-c52cd6c85461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2222dd-7e76-46d3-a6af-24d52b4a5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03fcaf-6713-486d-ab61-0dd8c900db2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
