{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21feb90-2a7a-4a53-80a7-22714db93437",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# BCQ to predict first 3D item set\n",
    "# Q Learning to predict the other 2 item sets \n",
    "#     Q Table: state = itemSetID\n",
    "#              action = itemSetID\n",
    "#\n",
    "# 0. split train data into training set and validation set\n",
    "# ----- Train BCQ -----------------\n",
    "# 1.1 prepare data for training set:\n",
    "#       step: 0, 1, 2, ..., 9\n",
    "#       state: userFeatures20D + [step]\n",
    "#       action: itemID\n",
    "# 1.2 Train BCQ\n",
    "#\n",
    "# ----- Train Q Learning ----------\n",
    "# 2.1 prepare data for training set:\n",
    "#     state: itemSetID\n",
    "#     action itemSetID\n",
    "# 2.2 Train Q Learning\n",
    "# \n",
    "# ----- Prediction ----------------\n",
    "# 3.1 transform userFeaturesTest to 20D by using PCA\n",
    "# 3.2 Make prediction of the first itemSet by using BCQModel, name it itemSet1\n",
    "# 3.3 use itemSet1 as state for QLModel to predict best itemSet2\n",
    "# 3.4 use itemSet2 as state for QLModel to predict best itemSet3\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c265706-3767-47fa-a41c-958e0ce0b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 28] No space left on device.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Multiprocessing threads: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3443570/3065129355.py:4: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
      "/tmp/ipykernel_3443570/3065129355.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  itemInfo = Items()\n"
     ]
    }
   ],
   "source": [
    "# 1. Split Train \n",
    "from DataPrep import *\n",
    "from tqdm import tqdm\n",
    "userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
    "# when training, userFeaturesTrain represent state\n",
    "N_ITEMS = 381\n",
    "# load item info\n",
    "from classes.Items import Items\n",
    "itemInfo = Items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2150bddc-23e4-40a8-8759-fee6a2b3f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction with PCA\n",
    "# comment this part out to use original user features \n",
    "import pandas as pd\n",
    "\n",
    "# cluster model of 20D\n",
    "from DataPrep import getClusterModel200_20D\n",
    "ClusterModel, clusterLabels = getClusterModel200_20D()\n",
    "\n",
    "from DataPrep import getPCATransformer\n",
    "PCAtransformer = getPCATransformer()\n",
    "userFeaturesTrain = pd.DataFrame(PCAtransformer.transform(userFeaturesTrain))\n",
    "userFeaturesVal = pd.DataFrame(PCAtransformer.transform(userFeaturesVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cffb70-9303-47e5-bd38-edc0f9e189ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 208069/208069 [00:42<00:00, 4932.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1.1 prepare data for training set\n",
    "import numpy as np\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "\n",
    "statesTrain = []\n",
    "actionsTrain = []\n",
    "rewardsTrain = []\n",
    "terminalTrain = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        statesTrain.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsTrain.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsTrain.append(itemInfo.getItemPrice(itemID))\n",
    "        else:\n",
    "            rewardsTrain.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        else:\n",
    "            terminalTrain.append(1) # game stop\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesTrain = np.array(statesTrain)\n",
    "actionsTrain = np.array(actionsTrain)\n",
    "rewardsTrain = np.array(rewardsTrain)\n",
    "terminalTrain = np.array(terminalTrain)\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf1ba22-d396-4102-8b5e-0aa210bea810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 52018/52018 [00:10<00:00, 5112.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1.1 prepare data for validation set\n",
    "statesVal = []\n",
    "actionsVal = []\n",
    "rewardsVal = []\n",
    "terminalVal = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesVal.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesVal.iloc[i])\n",
    "    itemList = recItemsVal[i]\n",
    "    purchase = purchaseLabelVal[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to val set\n",
    "        # append step to state\n",
    "        statesVal.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsVal.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsVal.append(itemInfo.getItemPrice(itemID))\n",
    "        else:\n",
    "            rewardsVal.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalVal.append(0) # game continue\n",
    "        else:\n",
    "            terminalVal.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesVal = np.array(statesVal)\n",
    "actionsVal = np.array(actionsVal)\n",
    "rewardsVal = np.array(rewardsVal)\n",
    "terminalVal = np.array(terminalVal)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19e43bf-75c8-45d3-b08a-1028f4d94b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures2_v2.pkl', 'wb') as file:\n",
    "    pickle.dump((statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaa01a8-2530-46bb-ad49-936e72a08dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures2_v2.pkl', 'rb') as file:\n",
    "    statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal = pickle.load(file)\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee377ed-9ed8-4d36-aab5-139dfa52c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 21:20.16 [debug    ] RoundIterator is selected.\n",
      "2021-08-17 21:20.16 [info     ] Directory is created at d3rlpy_logs/DiscreteBCQ_20210817212016\n",
      "2021-08-17 21:20.16 [warning  ] Skip building models since they're already built.\n",
      "2021-08-17 21:27.20 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_35276.pt\n",
      "2021-08-17 21:34.26 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_70552.pt\n",
      "2021-08-17 21:41.33 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_105828.pt\n",
      "2021-08-17 21:48.41 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_141104.pt\n",
      "2021-08-17 21:55.43 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_176380.pt\n",
      "2021-08-17 22:02.50 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_211656.pt\n",
      "2021-08-17 22:09.55 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_246932.pt\n",
      "2021-08-17 22:17.01 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_282208.pt\n",
      "2021-08-17 22:24.04 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_317484.pt\n",
      "2021-08-17 22:31.07 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_352760.pt\n",
      "2021-08-17 22:38.09 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_388036.pt\n",
      "2021-08-17 22:45.10 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_423312.pt\n",
      "2021-08-17 22:52.13 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_458588.pt\n",
      "2021-08-17 22:59.15 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_493864.pt\n",
      "2021-08-17 23:06.15 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_529140.pt\n",
      "2021-08-17 23:13.13 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_564416.pt\n",
      "2021-08-17 23:20.12 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_599692.pt\n",
      "2021-08-17 23:27.13 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_634968.pt\n",
      "2021-08-17 23:34.11 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_670244.pt\n",
      "2021-08-17 23:41.11 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_705520.pt\n",
      "2021-08-17 23:48.14 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_740796.pt\n",
      "2021-08-17 23:55.14 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_776072.pt\n",
      "2021-08-18 00:02.13 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_811348.pt\n",
      "2021-08-18 00:09.12 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_846624.pt\n",
      "2021-08-18 00:16.13 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210817212016/model_881900.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.00023121772432613838,\n",
       "   'time_algorithm_update': 0.011458939571393592,\n",
       "   'loss': 1101.7750068670607,\n",
       "   'time_step': 0.011967472653497657}),\n",
       " (2,\n",
       "  {'time_sample_batch': 0.00022424331177982806,\n",
       "   'time_algorithm_update': 0.011576907091879333,\n",
       "   'loss': 1377.555936580424,\n",
       "   'time_step': 0.012082560429538996}),\n",
       " (3,\n",
       "  {'time_sample_batch': 0.00025576197623882125,\n",
       "   'time_algorithm_update': 0.01153325472901043,\n",
       "   'loss': 1402.503883558196,\n",
       "   'time_step': 0.0120786996517123}),\n",
       " (4,\n",
       "  {'time_sample_batch': 0.00024646318530614634,\n",
       "   'time_algorithm_update': 0.011596293747594046,\n",
       "   'loss': 1328.6241755876456,\n",
       "   'time_step': 0.012126999831899844}),\n",
       " (5,\n",
       "  {'time_sample_batch': 0.00023319069957203274,\n",
       "   'time_algorithm_update': 0.011424832082359762,\n",
       "   'loss': 1229.9802922479068,\n",
       "   'time_step': 0.011935575754007983}),\n",
       " (6,\n",
       "  {'time_sample_batch': 0.00022762471119121218,\n",
       "   'time_algorithm_update': 0.011577660006884207,\n",
       "   'loss': 1177.5188194324214,\n",
       "   'time_step': 0.012084670287976934}),\n",
       " (7,\n",
       "  {'time_sample_batch': 0.00021706993772621557,\n",
       "   'time_algorithm_update': 0.0115526676488877,\n",
       "   'loss': 1138.2184781378285,\n",
       "   'time_step': 0.01204432485081709}),\n",
       " (8,\n",
       "  {'time_sample_batch': 0.00021626172334459286,\n",
       "   'time_algorithm_update': 0.01156650838944928,\n",
       "   'loss': 1128.7103046062975,\n",
       "   'time_step': 0.012062755520752816}),\n",
       " (9,\n",
       "  {'time_sample_batch': 0.00022874549343845772,\n",
       "   'time_algorithm_update': 0.011473627483267567,\n",
       "   'loss': 1112.2596823470312,\n",
       "   'time_step': 0.011979996259148421}),\n",
       " (10,\n",
       "  {'time_sample_batch': 0.00024648915884621577,\n",
       "   'time_algorithm_update': 0.011420937477427149,\n",
       "   'loss': 1113.278060531573,\n",
       "   'time_step': 0.011958498406780592}),\n",
       " (11,\n",
       "  {'time_sample_batch': 0.0002514951717611586,\n",
       "   'time_algorithm_update': 0.011415200603023139,\n",
       "   'loss': 1116.5019003014565,\n",
       "   'time_step': 0.011961063589553927}),\n",
       " (12,\n",
       "  {'time_sample_batch': 0.000248475421622627,\n",
       "   'time_algorithm_update': 0.011371072126172922,\n",
       "   'loss': 1120.6041211639622,\n",
       "   'time_step': 0.011908550539015642}),\n",
       " (13,\n",
       "  {'time_sample_batch': 0.00025838263411413233,\n",
       "   'time_algorithm_update': 0.01141222846766207,\n",
       "   'loss': 1120.0925718152425,\n",
       "   'time_step': 0.011972340411212064}),\n",
       " (14,\n",
       "  {'time_sample_batch': 0.000251028972737764,\n",
       "   'time_algorithm_update': 0.011407160545398433,\n",
       "   'loss': 1115.4585991524314,\n",
       "   'time_step': 0.01195662043805376}),\n",
       " (15,\n",
       "  {'time_sample_batch': 0.0002556645703945642,\n",
       "   'time_algorithm_update': 0.011318883139985208,\n",
       "   'loss': 1107.232798212036,\n",
       "   'time_step': 0.011872150700897137}),\n",
       " (16,\n",
       "  {'time_sample_batch': 0.00024990883256345803,\n",
       "   'time_algorithm_update': 0.011296129332119705,\n",
       "   'loss': 1102.02594303244,\n",
       "   'time_step': 0.011843782708628375}),\n",
       " (17,\n",
       "  {'time_sample_batch': 0.0002546998726995857,\n",
       "   'time_algorithm_update': 0.011304110075722126,\n",
       "   'loss': 1102.0183688171435,\n",
       "   'time_step': 0.011865644913734067}),\n",
       " (18,\n",
       "  {'time_sample_batch': 0.000259972812232145,\n",
       "   'time_algorithm_update': 0.011349924230591783,\n",
       "   'loss': 1109.3108993497399,\n",
       "   'time_step': 0.011920222039530371}),\n",
       " (19,\n",
       "  {'time_sample_batch': 0.00025134999569020097,\n",
       "   'time_algorithm_update': 0.011286306900290867,\n",
       "   'loss': 1129.78389392303,\n",
       "   'time_step': 0.011841877759320758}),\n",
       " (20,\n",
       "  {'time_sample_batch': 0.0002545087106888331,\n",
       "   'time_algorithm_update': 0.011314211228034679,\n",
       "   'loss': 1184.1349706108006,\n",
       "   'time_step': 0.011869721292895192}),\n",
       " (21,\n",
       "  {'time_sample_batch': 0.0002643320616957741,\n",
       "   'time_algorithm_update': 0.01139571345951406,\n",
       "   'loss': 1289.9987703568406,\n",
       "   'time_step': 0.011965677714939898}),\n",
       " (22,\n",
       "  {'time_sample_batch': 0.0002549644405439822,\n",
       "   'time_algorithm_update': 0.011340081624155318,\n",
       "   'loss': 1470.7374212851341,\n",
       "   'time_step': 0.011892977228834051}),\n",
       " (23,\n",
       "  {'time_sample_batch': 0.00025463421905185375,\n",
       "   'time_algorithm_update': 0.011311759969276802,\n",
       "   'loss': 1696.6342888047113,\n",
       "   'time_step': 0.011868344337062402}),\n",
       " (24,\n",
       "  {'time_sample_batch': 0.00024388489072751885,\n",
       "   'time_algorithm_update': 0.011324215028572277,\n",
       "   'loss': 1888.0611788560127,\n",
       "   'time_step': 0.011858362002036972}),\n",
       " (25,\n",
       "  {'time_sample_batch': 0.00025914272005994084,\n",
       "   'time_algorithm_update': 0.011350361637712835,\n",
       "   'loss': 2005.5523416207943,\n",
       "   'time_step': 0.01191951089305988})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 Train BCQ\n",
    "from d3rlpy.algos import DiscreteBCQ\n",
    "BCQModel = DiscreteBCQ(use_gpu = True)\n",
    "BCQModel.build_with_dataset(datasetTrain)\n",
    "BCQModel.fit(datasetTrain, \n",
    "    n_epochs = 25, verbose = False, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9836e897-f972-4c7d-a1f1-1c711c21b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Train Q Learning --------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ef361ac-e67d-4635-815d-554e663b7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 208069/208069 [00:21<00:00, 9736.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Prepare train data set\n",
    "#### state: step 0-2\n",
    "#### action: the itemSetID recommended\n",
    "#### reward: (item is purchased) * price\n",
    "#### nextState: next step\n",
    "#### to feed a set of (state, action, reward, nextState) to a Q table\n",
    "from tqdm import tqdm\n",
    "from classes.ItemSet import ItemSet3\n",
    "itemSet3 = ItemSet3()\n",
    "N_ACTIONS = itemSet3.getNSets()\n",
    "N_STATES = 3\n",
    "\n",
    "trainSetQL = []\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    recItems = recItemsTrain[i]\n",
    "    purLabel = purchaseLabelTrain[i]\n",
    "    for j in [0, 3, 6]: # process each Set3 at once\n",
    "        if j>2 and purLabel[0]*purLabel[1]*purLabel[2]==0:\n",
    "            # don't train if game stopped\n",
    "            break\n",
    "        if j>5 and purLabel[3]*purLabel[4]*purLabel[5]==0:\n",
    "            # don't train if game stopped\n",
    "            break\n",
    "        # calculate state:\n",
    "        state = j/3\n",
    "        # action: itemSetID\n",
    "        itemSet = [recItems[j], recItems[j+1], recItems[j+2]]\n",
    "        itemSetID = itemSet3.getSetID(itemSet)\n",
    "        action = itemSetID\n",
    "        # reward:\n",
    "        prices = [itemInfo.getItemPrice(itemSet[0]), itemInfo.getItemPrice(itemSet[1]), itemInfo.getItemPrice(itemSet[2])]\n",
    "        labels = [purLabel[j], purLabel[j+1], purLabel[j+2]]\n",
    "        reward = sum([prices[t]*labels[t] for t in range(3)])\n",
    "        # next state:\n",
    "        if j==6:\n",
    "            nextState = -1\n",
    "        else:\n",
    "            nextState = state+1\n",
    "        # append to train data set \n",
    "        trainSetQL.append((state, action, reward, nextState))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51d0ef-35f6-44f6-9f08-fe4f23cd7cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 95869/473522 [28:20<1:57:31, 53.56it/s]"
     ]
    }
   ],
   "source": [
    "# 2.2 Train QL model\n",
    "# initialize\n",
    "from classes import QLearning2\n",
    "from importlib import reload  \n",
    "QLearning2 = reload(QLearning2)\n",
    "\n",
    "print('N_ACTIONS: ' + str(N_ACTIONS) + ' N_STATES: ' + str(N_STATES))\n",
    "QLModel = QLearning2.QLearning(n_states = N_STATES, n_actions = N_ACTIONS)\n",
    "# train in parallel\n",
    "# QLModel.trainParallel(trainSetQL)\n",
    "QLModel.train(trainSetQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460a1c0-402d-4bc0-b879-dbfe4c29297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/model-BCQ-QL_v2.pkl', 'wb') as file:\n",
    "    pickle.dump((BCQModel, QLModel),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a5f68-ca01-4cf4-9994-5590bcad2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/model-BCQ-QL_v2.pkl', 'rb') as file:\n",
    "    BCQModel, QLModel = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426de0a2-9877-4c2c-9f13-62230110bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## PREDICTION ##########################################\n",
    "userIDs, userFeaturesTest = getUserFeaturesTestSet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56f3f698-b63f-40ec-ba25-e96a0dfe7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 transform userFeaturesTest to 20D by using PCA\n",
    "userFeaturesTest = pd.DataFrame(PCAtransformer.transform(userFeaturesTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504030e-172b-4417-8cab-36028c241bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 206096/206096 [00:22<00:00, 9229.85it/s] \n",
      "100% 381/381 [57:54<00:00,  9.12s/it]\n",
      "100% 1236576/1236576 [05:27<00:00, 3775.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# predict first 6 items with BCQ\n",
    "from classes.d3rlpy_wrapper import predictBestK, finalizeItemSetsTestSet\n",
    "statesTest = []  # this will be userFeaturesTest appended with a column of step = 0 to 8\n",
    "for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTest.iloc[i])\n",
    "    for step in range(6):\n",
    "        # append step to state\n",
    "        statesTest.append(state + [step])\n",
    "statesTest = np.array(statesTest)\n",
    "bestItems_6xSamples = predictBestK(BCQModel, statesTest, 6)\n",
    "bestFirst6tems = finalizeItemSetsTestSet(bestItems_6xSamples)\n",
    "\n",
    "\n",
    "# QLModel.initPredCache()\n",
    "# recItems_test = []\n",
    "# for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# # loop thru samples\n",
    "#     recItems = []  # recommended list for this sample\n",
    "#     # 3.2 Make prediction of the first itemSet by using BCQModel, name it itemSet1\n",
    "#     state = userFeaturesTest.iloc[i]  # first step of the game\n",
    "#     itemSetID1 = BCQModel.predict([np.array(state)])[0]\n",
    "#     recItems.extend(list(itemSet3.getItemSet(itemSetID1)))\n",
    "#     # 3.3 use itemSet1 as state for QLModel to predict best itemSet2\n",
    "#     # now stateID = itemSetID1\n",
    "#     candidateSetIDs = QLModel.predictBestK(itemSetID1, 20)\n",
    "#     for setID in candidateSetIDs:\n",
    "#         items = itemSet3.getItemSet(setID)\n",
    "#         if (items[0] not in recItems) and (items[1] not in recItems) and (items[2] not in recItems):\n",
    "#             # we have found a suitable solution for step 2\n",
    "#             itemSetID2 = setID\n",
    "#             recItems.extend(list(items))\n",
    "#             break\n",
    "#     # 3.4 use itemSet2 as state for QLModel to predict best itemSet3\n",
    "#     # now stateID = itemSetID2\n",
    "#     candidateSetIDs = QLModel.predictBestK(itemSetID2, 20)\n",
    "#     for setID in candidateSetIDs:\n",
    "#         items = itemSet3.getItemSet(setID)\n",
    "#         if (items[0] not in recItems) and (items[1] not in recItems) and (items[2] not in recItems):\n",
    "#             # we have found a suitable solution for step 2\n",
    "#             itemSetID3 = setID\n",
    "#             recItems.extend(list(items))\n",
    "#             break\n",
    "#     recItems_test.append(recItems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e143b8f-6d91-457d-ba22-fde228928ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1236576/1236576 [00:11<00:00, 104933.51it/s]\n"
     ]
    }
   ],
   "source": [
    "bestFirst6tems = finalizeItemSetsTestSet(statesTest, bestItems_3xSamples, 6)\n",
    "assert len(bestFirst6tems)==len(userIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c335e-71a7-4034-b84f-2f718be9fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict last 3 items with QL\n",
    "bestItemSetIDs = QLModel.predictBestK(2, 100)\n",
    "finalItems = []\n",
    "for i in tqdm(range(len(bestFirst6tems))):\n",
    "    first6 = bestFirst6tems[i]\n",
    "    for setID in bestItemSetIDs:\n",
    "        items = itemSet3.getItemSet(setID)\n",
    "        if (items[0] not in first6) and (items[1] not in first6) and (items[2] not in first6):\n",
    "            finalItems.append(first6 + list(items))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1890925-6a7f-4a35-a50d-5a75a79cb971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[220, 196, 221, 95, 97, 48], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 48], [220, 196, 221, 98, 97, 29], [220, 196, 218, 240, 238, 29], [220, 196, 221, 218, 97, 29], [220, 196, 218, 221, 98, 29], [220, 196, 221, 95, 97, 48], [220, 196, 221, 95, 97, 42], [220, 196, 221, 218, 97, 29], [220, 196, 218, 221, 98, 29], [220, 196, 218, 240, 238, 29], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 48], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 42], [220, 196, 218, 240, 98, 29], [220, 196, 221, 95, 97, 48], [220, 196, 221, 218, 97, 29], [220, 196, 218, 240, 238, 29], [220, 196, 218, 240, 238, 29], [220, 196, 218, 221, 98, 29], [220, 196, 218, 240, 238, 29], [220, 196, 218, 221, 98, 29], [220, 196, 218, 240, 221, 29], [220, 196, 221, 95, 97, 48], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 48], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 42], [220, 196, 221, 218, 97, 29], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 48], [220, 196, 221, 218, 97, 29], [220, 196, 221, 95, 97, 42], [220, 196, 218, 240, 238, 29], [220, 196, 221, 218, 97, 29], [220, 196, 218, 240, 238, 29], [220, 196, 221, 95, 97, 48], [220, 196, 218, 240, 238, 29], [220, 196, 221, 95, 97, 42], [220, 196, 221, 98, 97, 29], [220, 196, 221, 95, 97, 48], [220, 196, 218, 240, 238, 29], [220, 196, 221, 95, 97, 42], [220, 196, 221, 98, 97, 29], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 42], [220, 196, 221, 95, 97, 42]]\n"
     ]
    }
   ],
   "source": [
    "print(bestFirst6tems[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f67add-ce76-457a-a2ed-97f4284b9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write recommended items to output csv file\n",
    "from classes.output import writeOutput\n",
    "writeOutput(recItems_test, 'BCQ-QLearning_v1.csv', userIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd948d1-19fc-4c28-a2f4-c52cd6c85461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2222dd-7e76-46d3-a6af-24d52b4a5267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03fcaf-6713-486d-ab61-0dd8c900db2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
