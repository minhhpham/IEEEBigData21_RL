{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Implementation of DQN.\n",
    "#     State: (Click History, User Portraits) (note: purchase timestamp is not available in testset)\n",
    "#     Action: itemID (each sample is split into 9 steps)\n",
    "#     Rewards: Total price of purchased items\n",
    "# 0. split train data into training set and validation set\n",
    "# 1. prepare data for DQN from training set\n",
    "# 2. prepare data for DQN from validation set\n",
    "# 3. train DQN\n",
    "# 4. make suggestions for validation set\n",
    "# 5. Calculate Metrics 1 for our suggestions\n",
    "# 6. Generate suggestions for provided testset for true scoring\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Multiprocessing threads: 31\n"
     ]
    }
   ],
   "source": [
    "# 0. Split Train into training set and validation set\n",
    "from DataPrep import *\n",
    "from tqdm import tqdm\n",
    "userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
    "# when training, userFeaturesTrain represent state\n",
    "N_ITEMS = 381\n",
    "# load item price\n",
    "itemInfo = pd.read_csv('/tf/shared/item_info.csv', ' ')\n",
    "itemInfo = itemInfo.sort_values(by = 'item_id')\n",
    "itemPrice = itemInfo.price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction with PCA\n",
    "# comment this part out to use original user features \n",
    "import pandas as pd\n",
    "\n",
    "from DataPrep import getPCATransformer70\n",
    "PCAtransformer = getPCATransformer70()\n",
    "userFeaturesTrain = pd.DataFrame(PCAtransformer.transform(userFeaturesTrain))\n",
    "userFeaturesVal = pd.DataFrame(PCAtransformer.transform(userFeaturesVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208069/208069 [00:30<00:00, 6894.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. prepare data for training set\n",
    "import numpy as np\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "\n",
    "statesTrain = []\n",
    "actionsTrain = []\n",
    "rewardsTrain = []\n",
    "terminalTrain = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        statesTrain.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsTrain.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsTrain.append(itemPrice[itemID-1]) # itemID-1 becuase itemPrice is a 0-based array\n",
    "        else:\n",
    "            rewardsTrain.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalTrain.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalTrain.append(0) # game continue\n",
    "        else:\n",
    "            terminalTrain.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesTrain = np.array(statesTrain)\n",
    "actionsTrain = np.array(actionsTrain)\n",
    "rewardsTrain = np.array(rewardsTrain)\n",
    "terminalTrain = np.array(terminalTrain)\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52018/52018 [00:06<00:00, 7666.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2. prepare data for validation set\n",
    "statesVal = []\n",
    "actionsVal = []\n",
    "rewardsVal = []\n",
    "terminalVal = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "for i in tqdm(range(userFeaturesVal.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesVal.iloc[i])\n",
    "    itemList = recItemsVal[i]\n",
    "    purchase = purchaseLabelVal[i]\n",
    "    for step in range(9):\n",
    "        # check if game is still running\n",
    "        if step>2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>5 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to val set\n",
    "        # append step to state\n",
    "        statesVal.append(state + [step])\n",
    "        # action = itemID\n",
    "        itemID = itemList[step]\n",
    "        actionsVal.append(itemID)\n",
    "        # calculate reward\n",
    "        if purchase[step]==1:\n",
    "            rewardsVal.append(itemPrice[itemID-1]) # itemID-1 becuase itemPrice is a 0-based array\n",
    "        else:\n",
    "            rewardsVal.append(0)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step<2:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==2 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<5:\n",
    "            terminalVal.append(0) # game continue\n",
    "        elif step==5 and purchase[3]*purchase[4]*purchase[5]:\n",
    "            terminalVal.append(1) # game stop\n",
    "        elif step<8:\n",
    "            terminalVal.append(0) # game continue\n",
    "        else:\n",
    "            terminalVal.append(1) # game stop\n",
    "\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesVal = np.array(statesVal)\n",
    "actionsVal = np.array(actionsVal)\n",
    "rewardsVal = np.array(rewardsVal)\n",
    "terminalVal = np.array(terminalVal)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-70DFeatures.pkl', 'wb') as file:\n",
    "    pickle.dump((statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-70DFeatures.pkl', 'rb') as file:\n",
    "    statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal = pickle.load(file)\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-28 12:12.22 [debug    ] RoundIterator is selected.\n",
      "2021-08-28 12:12.22 [info     ] Directory is created at d3rlpy_logs/DiscreteBCQ_20210828121222\n",
      "2021-08-28 12:12.22 [warning  ] Skip building models since they're already built.\n",
      "2021-08-28 12:15.26 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210828121222/model_35272.pt\n",
      "2021-08-28 12:18.28 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210828121222/model_70544.pt\n",
      "2021-08-28 12:21.33 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210828121222/model_105816.pt\n",
      "2021-08-28 12:24.34 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210828121222/model_141088.pt\n",
      "2021-08-28 12:27.40 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210828121222/model_176360.pt\n",
      "2021-08-28 12:30.46 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210828121222/model_211632.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c12d53b00be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md3rlpy_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRLModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainAllModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/shared/classes/d3rlpy_wrapper.py\u001b[0m in \u001b[0;36mtrainAllModels\u001b[0;34m(self, n_epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#             self.DQN.fit(self.datasetTrain, n_epochs=n_epochs, verbose=False, show_progress=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#             self.DoubleDQN.fit(self.datasetTrain, n_epochs=n_epochs, verbose=False, show_progress=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscreteBCQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasetTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;31m#             self.DiscreteCQL.fit(self.datasetTrain, n_epochs=n_epochs, verbose=False, show_progress=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, n_epochs, n_steps, n_steps_per_epoch, save_metrics, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, eval_episodes, save_interval, scorers, shuffle, callback)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[0;32m--> 406\u001b[0;31m         results = list(\n\u001b[0m\u001b[1;32m    407\u001b[0m             self.fitter(\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/base.py\u001b[0m in \u001b[0;36mfitter\u001b[0;34m(self, dataset, n_epochs, n_steps, n_steps_per_epoch, save_metrics, experiment_name, with_timestamp, logdir, verbose, show_progress, tensorboard_dir, eval_episodes, save_interval, scorers, shuffle, callback)\u001b[0m\n\u001b[1;32m    626\u001b[0m                     \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"algorithm_update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                     \u001b[0;31m# record metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/base.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/algos/bcq.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTransitionMiniBatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMPL_NOT_INITIALIZED_ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_update_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/torch_utility.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mset_train_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/torch_utility.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/d3rlpy/algos/torch/dqn_impl.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mq_tpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mset_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from classes import d3rlpy_wrapper\n",
    "from importlib import reload\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "d3rlpy_wrapper = reload(d3rlpy_wrapper)\n",
    "\n",
    "wrapper = d3rlpy_wrapper.RLModelWrapper(datasetTrain)\n",
    "wrapper.trainAllModels(n_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models to checkpoints\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/models-3D-70DFeatures.pkl', 'wb') as file:\n",
    "    pickle.dump((wrapper.DQN, wrapper.DoubleDQN, wrapper.DiscreteBCQ, wrapper.DiscreteCQL),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "from classes import d3rlpy_wrapper\n",
    "wrapper = d3rlpy_wrapper.RLModelWrapper(datasetTrain, datasetVal)\n",
    "with open('/tf/shared/checkpoints/models-7D-20DFeatures.pkl', 'rb') as file:\n",
    "    wrapper.DQN, wrapper.DoubleDQN, wrapper.DiscreteBCQ, wrapper.DiscreteCQL = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Now we prepare test set to make prediction\n",
    "userIDs, userFeaturesTest = getUserFeaturesTestSet()\n",
    "statesTest = []  # this will be userFeaturesTest appended with a column of step = 0 to 8\n",
    "for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTest.iloc[i])\n",
    "    for step in range(9):\n",
    "        # append step to state\n",
    "        statesTest.append(state + [step])\n",
    "\n",
    "print(len(statesTest))\n",
    "statesTest = np.array(statesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prediction for this expanded test sets, number of rows = nrows(test set) * 9\n",
    "itemSetDQN, itemSetDoubleDQN, itemSetDiscreteBCQ, itemSetDiscreteCQL = wrapper.predict9ItemsAllModels(statesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatenate multiple rows of itemSet into a single set for each user sample\n",
    "# for each sample:\n",
    "#     finalSet = []\n",
    "#     for each step in sample:\n",
    "#          iterate thru recommended items and add to finalSet if that item is not already in finalSet\n",
    "def finalizeItemSetsTestSet(statesInput, itemSet):\n",
    "    output = []\n",
    "    for i in tqdm(range(statesInput.shape[0])):\n",
    "        # loop through expanded samples\n",
    "        state = list(statesInput[i])\n",
    "        step = state[len(state)-1]\n",
    "        if step==0: # init new finalItemSet\n",
    "            finalItemSet = []\n",
    "        # try to add new item to finalItemSet, based on their highest value\n",
    "        for item in itemSet[i]:\n",
    "            if item not in finalItemSet:\n",
    "                finalItemSet.append(item)\n",
    "                break\n",
    "        # export finalItemSet once reaching step 8\n",
    "        if step==8:\n",
    "            assert len(finalItemSet)==9\n",
    "            output.append(finalItemSet)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalItemSetDQN = finalizeItemSetsTestSet(statesTest, itemSetDQN)\n",
    "# finalItemSetDoubleDQN = finalizeItemSetsTestSet(statesTest, itemSetDoubleDQN)\n",
    "finalItemSetDiscreteBCQ = finalizeItemSetsTestSet(statesTest, itemSetDiscreteBCQ)\n",
    "# finalItemSetDiscreteCQL = finalizeItemSetsTestSet(statesTest, itemSetDiscreteCQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save results to output\n",
    "# format data according to submission format and write to file\n",
    "def writeOutput(finalItemSet, outFileName, userIDs_ = userIDs, outDir = '/tf/shared/outputs/'):\n",
    "    outFile = outDir + outFileName\n",
    "    f = open(outFile, \"w\")\n",
    "    f.write('id,itemids')\n",
    "    for i in range(len(userIDs_)):\n",
    "        f.write('\\n')\n",
    "        itemList = finalItemSet[i]\n",
    "        itemString = ' '.join([str(j) for j in itemList])\n",
    "        outString = str(userIDs_[i]) + ',' + itemString\n",
    "        f.write(outString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeOutput(finalItemSetDQN, 'DQN_20DFeatures.csv')\n",
    "# writeOutput(finalItemSetDoubleDQN, 'DoubleDQN_20DFeatures.csv')\n",
    "writeOutput(finalItemSetDiscreteBCQ, 'DiscreteBCQ_70DFeatures.csv')\n",
    "# writeOutput(finalItemSetDiscreteCQL, 'DiscreteCQL_20DFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################### Now we calculate our Metrics1 on the 4 models ##################################\n",
    "from classes.Metrics import Metrics\n",
    "metrics = Metrics(recItemsVal, purchaseLabelVal, itemPrice)\n",
    "\n",
    "################### generate prediction for expanded val set\n",
    "itemSetDQN_val, itemSetDoubleDQN_val, itemSetDiscreteBCQ_val, itemSetDiscreteCQL_val = wrapper.predict9ItemsAllModels(statesVal)\n",
    "\n",
    "# function to concatenate multiple rows of val itemSet into a single set for each user sample\n",
    "# because of the way we organize data, each sample is divided into multiple rows\n",
    "def finalizeItemSets(statesInput, itemSet):\n",
    "    \"\"\" statesInput: input for models to generate itemSet \"\"\"\n",
    "    finalItemSet = []\n",
    "    for i in tqdm(range(statesInput.shape[0])):\n",
    "    # loop thru multiple rows of samples\n",
    "        # get step of the game in this row (step is range from 0 to 8), step is the last column\n",
    "        # we only get itemset from the first step = 0\n",
    "        state = list(statesInput[i])\n",
    "        step = state[len(state)-1]\n",
    "        if step==0:\n",
    "            finalItemSet.append(itemSet[i])\n",
    "    return finalItemSet\n",
    "\n",
    "# finalItemSetDQN_val = finalizeItemSets(statesVal, itemSetDQN_val)\n",
    "# finalItemSetDoubleDQN_val = finalizeItemSets(statesVal, itemSetDoubleDQN_val)\n",
    "finalItemSetDiscreteBCQ_val = finalizeItemSets(statesVal, itemSetDiscreteBCQ_val)\n",
    "# finalItemSetDiscreteCQL_val = finalizeItemSets(statesVal, itemSetDiscreteCQL_val)\n",
    "# assert len(finalItemSetDQN_val) == userFeaturesVal.shape[0]\n",
    "# assert len(finalItemSetDoubleDQN_val) == userFeaturesVal.shape[0]\n",
    "assert len(finalItemSetDiscreteBCQ_val) == userFeaturesVal.shape[0]\n",
    "# assert len(finalItemSetDiscreteCQL_val) == userFeaturesVal.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics1_DQN = metrics.calculate_metrics1(finalItemSetDQN_val)\n",
    "# metrics1_DoubleDQN = metrics.calculate_metrics1(finalItemSetDoubleDQN_val)\n",
    "metrics1_DiscreteBCQ = metrics.calculate_metrics1(finalItemSetDiscreteBCQ_val)\n",
    "# metrics1_DiscreteCQL = metrics.calculate_metrics1(finalItemSetDiscreteCQL_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics1_DQN)\n",
    "# print(metrics1_DoubleDQN)\n",
    "print(metrics1_DiscreteBCQ)\n",
    "# print(metrics1_DiscreteCQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
