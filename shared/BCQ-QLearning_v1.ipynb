{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21feb90-2a7a-4a53-80a7-22714db93437",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# BCQ to predict first 3D item set\n",
    "# Q Learning to predict the other 2 item sets \n",
    "#     Q Table: state = itemSetID\n",
    "#              action = itemSetID\n",
    "#\n",
    "# 0. split train data into training set and validation set\n",
    "# ----- Train BCQ -----------------\n",
    "# 1.1 prepare data for training set:\n",
    "#       state: 0, 1, 2\n",
    "#       action: itemSetID\n",
    "# 1.2 Train BCQ\n",
    "#\n",
    "# ----- Train Q Learning ----------\n",
    "# 2.1 prepare data for training set:\n",
    "#     state: itemSetID\n",
    "#     action itemSetID\n",
    "# 2.2 Train Q Learning\n",
    "# \n",
    "# ----- Prediction ----------------\n",
    "# 3.1 transform userFeaturesTest to 20D by using PCA\n",
    "# 3.2 Make prediction of the first itemSet by using BCQModel, name it itemSet1\n",
    "# 3.3 use itemSet1 as state for QLModel to predict best itemSet2\n",
    "# 3.4 use itemSet2 as state for QLModel to predict best itemSet3\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c265706-3767-47fa-a41c-958e0ce0b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2094004/3257893058.py:3: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
      "/tmp/ipykernel_2094004/3257893058.py:10: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  itemInfo = Items()\n"
     ]
    }
   ],
   "source": [
    "# 1. Split Train \n",
    "from DataPrep import *\n",
    "userFeaturesTrain, recItemsTrain, purchaseLabelTrain, userFeaturesVal, recItemsVal, purchaseLabelVal = splitTrainSet()\n",
    "userFeaturesTrain = pd.concat((userFeaturesTrain, userFeaturesVal), ignore_index=True)\n",
    "recItemsTrain = np.vstack((recItemsTrain, recItemsVal))\n",
    "purchaseLabelTrain = np.vstack((purchaseLabelTrain, purchaseLabelVal))\n",
    "\n",
    "# load item info\n",
    "from classes.Items import Items\n",
    "itemInfo = Items()\n",
    "# translator from (ID1, ID2, ID3) to setID\n",
    "from classes.ItemSet import ItemSet3\n",
    "itemSet3 = ItemSet3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2150bddc-23e4-40a8-8759-fee6a2b3f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction with PCA\n",
    "# comment this part out to use original user features \n",
    "import pandas as pd\n",
    "\n",
    "# cluster model of 20D\n",
    "from DataPrep import getClusterModel200_20D\n",
    "ClusterModel, clusterLabels = getClusterModel200_20D()\n",
    "\n",
    "from DataPrep import getPCATransformer\n",
    "PCAtransformer = getPCATransformer()\n",
    "userFeaturesTrain = pd.DataFrame(PCAtransformer.transform(userFeaturesTrain))\n",
    "userFeaturesVal = pd.DataFrame(PCAtransformer.transform(userFeaturesVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cffb70-9303-47e5-bd38-edc0f9e189ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 260087/260087 [00:53<00:00, 4832.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1.1 prepare data for training set\n",
    "import numpy as np\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "\n",
    "statesTrain = []\n",
    "actionsTrain = []\n",
    "rewardsTrain = []\n",
    "terminalTrain = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(3):\n",
    "        # check if game is still running\n",
    "        if step>0 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>1 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        if step==0:\n",
    "            step_OneHot = [1, 0, 0]\n",
    "        elif step==1:\n",
    "            step_OneHot = [0, 1, 0]\n",
    "        else:\n",
    "            step_OneHot = [0, 0, 1]\n",
    "        statesTrain.append(state + step_OneHot)\n",
    "        # action = itemSetID\n",
    "        itemIDs = (itemList[step*3], itemList[step*3+1], itemList[step*3+2])\n",
    "        itemSetID = itemSet3.getSetID(itemIDs)\n",
    "        actionsTrain.append(itemSetID)\n",
    "        # calculate reward\n",
    "        price0 = itemInfo.getItemPrice(itemIDs[0])\n",
    "        price1 = itemInfo.getItemPrice(itemIDs[1])\n",
    "        price2 = itemInfo.getItemPrice(itemIDs[2])\n",
    "        purch0 = purchase[step*3]\n",
    "        purch1 = purchase[step*3+1]\n",
    "        purch2 = purchase[step*3+2]\n",
    "        reward = price0*purch0 + price1*purch1 + price2*purch2\n",
    "        rewardsTrain.append(reward)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step!=2:\n",
    "            if purch0*purch1*purch2 == 1: # game continue if all is 1\n",
    "                terminalTrain.append(0)\n",
    "            else:\n",
    "                terminalTrain.append(1) # game stop\n",
    "        else: # game stop at step 2\n",
    "            terminalTrain.append(1)\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesTrain = np.array(statesTrain)\n",
    "actionsTrain = np.array(actionsTrain)\n",
    "rewardsTrain = np.array(rewardsTrain)\n",
    "terminalTrain = np.array(terminalTrain)\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf1ba22-d396-4102-8b5e-0aa210bea810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 260087/260087 [00:54<00:00, 4789.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1.1 prepare data for validation set\n",
    "statesVal = []\n",
    "actionsVal = []\n",
    "rewardsVal = []\n",
    "terminalVal = []  # terminal flag: 0 = game continue, 1 = game stop\n",
    "\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    itemList = recItemsTrain[i]\n",
    "    purchase = purchaseLabelTrain[i]\n",
    "    for step in range(3):\n",
    "        # check if game is still running\n",
    "        if step>0 and purchase[0]*purchase[1]*purchase[2]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        if step>1 and purchase[3]*purchase[4]*purchase[5]==0:\n",
    "            # stop adding to data set if game stopped\n",
    "            break\n",
    "        # after passing check, we can add new record to train set\n",
    "        # append step to state\n",
    "        if step==0:\n",
    "            step_OneHot = [1, 0, 0]\n",
    "        elif step==1:\n",
    "            step_OneHot = [0, 1, 0]\n",
    "        else:\n",
    "            step_OneHot = [0, 0, 1]\n",
    "        statesVal.append(state + step_OneHot)\n",
    "        # action = itemSetID\n",
    "        itemIDs = (itemList[step*3], itemList[step*3+1], itemList[step*3+2])\n",
    "        itemSetID = itemSet3.getSetID(itemIDs)\n",
    "        actionsVal.append(itemSetID)\n",
    "        # calculate reward\n",
    "        price0 = itemInfo.getItemPrice(itemIDs[0])\n",
    "        price1 = itemInfo.getItemPrice(itemIDs[1])\n",
    "        price2 = itemInfo.getItemPrice(itemIDs[2])\n",
    "        purch0 = purchase[step*3]\n",
    "        purch1 = purchase[step*3+1]\n",
    "        purch2 = purchase[step*3+2]\n",
    "        reward = price0*purch0 + price1*purch1 + price2*purch2\n",
    "        rewardsVal.append(reward)\n",
    "        # terminal flag: determine by looking at previous purchase flags\n",
    "        if step!=2:\n",
    "            if purch0*purch1*purch2 == 1: # game continue if all is 1\n",
    "                terminalVal.append(0)\n",
    "            else:\n",
    "                terminalVal.append(1) # game stop\n",
    "        else: # game stop at step 2\n",
    "            terminalVal.append(1)\n",
    "\n",
    "# ### terminal flags: all 1\n",
    "statesVal = np.array(statesVal)\n",
    "actionsVal = np.array(actionsVal)\n",
    "rewardsVal = np.array(rewardsVal)\n",
    "terminalVal = np.array(terminalVal)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19e43bf-75c8-45d3-b08a-1028f4d94b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures2.pkl', 'wb') as file:\n",
    "    pickle.dump((statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaa01a8-2530-46bb-ad49-936e72a08dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/data-3D-20DFeatures2.pkl', 'rb') as file:\n",
    "    statesTrain, actionsTrain, rewardsTrain, terminalTrain, statesVal, actionsVal, rewardsVal, terminalVal = pickle.load(file)\n",
    "\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "datasetTrain = MDPDataset(statesTrain, actionsTrain, rewardsTrain, terminalTrain, discrete_action = True)\n",
    "datasetVal = MDPDataset(statesVal, actionsVal, rewardsVal, terminalVal, discrete_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee377ed-9ed8-4d36-aab5-139dfa52c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-14 22:48.02 [debug    ] RoundIterator is selected.\n",
      "2021-08-14 22:48.02 [info     ] Directory is created at d3rlpy_logs/DiscreteBCQ_20210814224802\n",
      "2021-08-14 22:48.02 [warning  ] Skip building models since they're already built.\n",
      "2021-08-14 22:51.14 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_10367.pt\n",
      "2021-08-14 22:54.26 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_20734.pt\n",
      "2021-08-14 22:57.39 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_31101.pt\n",
      "2021-08-14 23:00.52 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_41468.pt\n",
      "2021-08-14 23:04.05 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_51835.pt\n",
      "2021-08-14 23:07.19 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_62202.pt\n",
      "2021-08-14 23:10.32 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_72569.pt\n",
      "2021-08-14 23:13.47 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_82936.pt\n",
      "2021-08-14 23:17.00 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_93303.pt\n",
      "2021-08-14 23:20.14 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteBCQ_20210814224802/model_103670.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.0001515564836185809,\n",
       "   'time_algorithm_update': 0.01805083475934398,\n",
       "   'loss': 4282.665614854753,\n",
       "   'time_step': 0.018301082138064466}),\n",
       " (2,\n",
       "  {'time_sample_batch': 0.00015867410727679656,\n",
       "   'time_algorithm_update': 0.018053972952228117,\n",
       "   'loss': 5393.518721679028,\n",
       "   'time_step': 0.018312125837514265}),\n",
       " (3,\n",
       "  {'time_sample_batch': 0.00015568935596300113,\n",
       "   'time_algorithm_update': 0.0180574414400513,\n",
       "   'loss': 6499.4272664878645,\n",
       "   'time_step': 0.018311882497397985}),\n",
       " (4,\n",
       "  {'time_sample_batch': 0.00015911578074179563,\n",
       "   'time_algorithm_update': 0.018094284320344482,\n",
       "   'loss': 5442.25285130204,\n",
       "   'time_step': 0.018352510545733718}),\n",
       " (5,\n",
       "  {'time_sample_batch': 0.0001569997267356498,\n",
       "   'time_algorithm_update': 0.0181235435718026,\n",
       "   'loss': 4624.050513665564,\n",
       "   'time_step': 0.018379950277299606}),\n",
       " (6,\n",
       "  {'time_sample_batch': 0.00015844944140438956,\n",
       "   'time_algorithm_update': 0.018198276009959335,\n",
       "   'loss': 4637.572388401806,\n",
       "   'time_step': 0.018456781728065058}),\n",
       " (7,\n",
       "  {'time_sample_batch': 0.00016078620565492988,\n",
       "   'time_algorithm_update': 0.018160773091736165,\n",
       "   'loss': 4394.483111400941,\n",
       "   'time_step': 0.01842051165490506}),\n",
       " (8,\n",
       "  {'time_sample_batch': 0.00015651467934953703,\n",
       "   'time_algorithm_update': 0.018254279906349334,\n",
       "   'loss': 2881.868167135747,\n",
       "   'time_step': 0.01851088561213234}),\n",
       " (9,\n",
       "  {'time_sample_batch': 0.00016109175492105734,\n",
       "   'time_algorithm_update': 0.01815705981493295,\n",
       "   'loss': 2704.535573870119,\n",
       "   'time_step': 0.018417364101901146}),\n",
       " (10,\n",
       "  {'time_sample_batch': 0.00015896749068700187,\n",
       "   'time_algorithm_update': 0.018217077178896205,\n",
       "   'loss': 2566.7614268150855,\n",
       "   'time_step': 0.01847571419165497})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 Train BCQ\n",
    "from d3rlpy.algos import DiscreteBCQ\n",
    "BCQModel = DiscreteBCQ(use_gpu = True)\n",
    "BCQModel.build_with_dataset(datasetTrain)\n",
    "BCQModel.fit(datasetTrain, \n",
    "    eval_episodes = datasetVal,\n",
    "    n_epochs = 10, verbose = False, show_progress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9836e897-f972-4c7d-a1f1-1c711c21b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Train Q Learning --------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef361ac-e67d-4635-815d-554e663b7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 260087/260087 [00:52<00:00, 4924.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Prepare train data set\n",
    "#### state: =N_STATES-1 if first set, =previous recommended itemSetID otherwise\n",
    "#### action: the itemSetID recommended\n",
    "#### reward: (item is purchased) * price\n",
    "#### nextState: -1 if we are at 3rd set (game terminated), =itemSetID otherwise\n",
    "#### to feed a set of (state, action, reward, nextState) to a Q table\n",
    "from tqdm import tqdm\n",
    "from classes.ItemSet import ItemSet3\n",
    "itemSet3 = ItemSet3()\n",
    "N_ACTIONS = itemSet3.getNSets()\n",
    "N_STATES = N_ACTIONS + 1 # 1 for initial state\n",
    "\n",
    "trainSetQL = []\n",
    "for i in tqdm(range(userFeaturesTrain.shape[0])):\n",
    "# loop through samples\n",
    "    state = list(userFeaturesTrain.iloc[i])\n",
    "    recItems = recItemsTrain[i]\n",
    "    purLabel = purchaseLabelTrain[i]\n",
    "    for j in [0, 3, 6]: # process each Set3 at once\n",
    "        if j>2 and purLabel[0]*purLabel[1]*purLabel[2]==0:\n",
    "            # don't train if game stopped\n",
    "            break\n",
    "        if j>5 and purLabel[3]*purLabel[4]*purLabel[5]==0:\n",
    "            # don't train if game stopped\n",
    "            break\n",
    "        # calculate state:\n",
    "        if j==0:\n",
    "            state = N_STATES-1\n",
    "        else:\n",
    "            state = itemSetID # previous recommened itemSet\n",
    "        # action: itemSetID\n",
    "        itemSet = [recItems[j], recItems[j+1], recItems[j+2]]\n",
    "        itemSetID = itemSet3.getSetID(itemSet)\n",
    "        action = itemSetID\n",
    "        # reward:\n",
    "        prices = [itemInfo.getItemPrice(itemSet[0]), itemInfo.getItemPrice(itemSet[1]), itemInfo.getItemPrice(itemSet[2])]\n",
    "        labels = [purLabel[j], purLabel[j+1], purLabel[j+2]]\n",
    "        reward = sum([prices[t]*labels[t] for t in range(3)])\n",
    "        # next state:\n",
    "        if j==6:\n",
    "            nextState = -1\n",
    "        else:\n",
    "            nextState = itemSetID\n",
    "        # append to train data set \n",
    "        trainSetQL.append((state, action, reward, nextState))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b51d0ef-35f6-44f6-9f08-fe4f23cd7cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_ACTIONS: 112368 N_STATES: 112369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 591837/591837 [4:54:06<00:00, 33.54it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 2.2 Train QL model\n",
    "# initialize\n",
    "from classes import QLearning2\n",
    "from importlib import reload  \n",
    "QLearning2 = reload(QLearning2)\n",
    "\n",
    "print('N_ACTIONS: ' + str(N_ACTIONS) + ' N_STATES: ' + str(N_STATES))\n",
    "QLModel = QLearning2.QLearning(n_states = N_STATES, n_actions = N_ACTIONS)\n",
    "# train in parallel\n",
    "# QLModel.trainParallel(trainSetQL)\n",
    "QLModel.train(trainSetQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9460a1c0-402d-4bc0-b879-dbfe4c29297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/model-BCQ-QL.pkl', 'wb') as file:\n",
    "    pickle.dump((BCQModel, QLModel),\n",
    "                file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "246a5f68-ca01-4cf4-9994-5590bcad2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload checkpoint\n",
    "import pickle\n",
    "with open('/tf/shared/checkpoints/model-BCQ-QL.pkl', 'rb') as file:\n",
    "    BCQModel, QLModel = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "426de0a2-9877-4c2c-9f13-62230110bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## PREDICTION ##########################################\n",
    "userIDs, userFeaturesTest = getUserFeaturesTestSet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56f3f698-b63f-40ec-ba25-e96a0dfe7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 transform userFeaturesTest to 20D by using PCA\n",
    "userFeaturesTest = pd.DataFrame(PCAtransformer.transform(userFeaturesTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504030e-172b-4417-8cab-36028c241bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QLModel.initPredCache()\n",
    "recItems_test = []\n",
    "for i in tqdm(range(userFeaturesTest.shape[0])):\n",
    "# loop thru samples\n",
    "    recItems = []  # recommended list for this sample\n",
    "    # 3.2 Make prediction of the first itemSet by using BCQModel, name it itemSet1\n",
    "    state = list(userFeaturesTest.iloc[i]) + [1, 0, 0]  # first step of the game\n",
    "    itemSetID1 = BCQModel.predict([np.array(state)])[0]\n",
    "    recItems.extend(list(itemSet3.getItemSet(itemSetID1)))\n",
    "    # 3.3 use itemSet1 as state for QLModel to predict best itemSet2\n",
    "    # now stateID = itemSetID1\n",
    "    candidateSetIDs = QLModel.predictBestK(itemSetID1, 20)\n",
    "    for setID in candidateSetIDs:\n",
    "        items = itemSet3.getItemSet(setID)\n",
    "        if (items[0] not in recItems) and (items[1] not in recItems) and (items[2] not in recItems):\n",
    "            # we have found a suitable solution for step 2\n",
    "            itemSetID2 = setID\n",
    "            recItems.extend(list(items))\n",
    "            break\n",
    "    # 3.4 use itemSet2 as state for QLModel to predict best itemSet3\n",
    "    # now stateID = itemSetID2\n",
    "    candidateSetIDs = QLModel.predictBestK(itemSetID2, 20)\n",
    "    for setID in candidateSetIDs:\n",
    "        items = itemSet3.getItemSet(setID)\n",
    "        if (items[0] not in recItems) and (items[1] not in recItems) and (items[2] not in recItems):\n",
    "            # we have found a suitable solution for step 2\n",
    "            itemSetID3 = setID\n",
    "            recItems.extend(list(items))\n",
    "            break\n",
    "    recItems_test.append(recItems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f67add-ce76-457a-a2ed-97f4284b9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write recommended items to output csv file\n",
    "from classes.output import writeOutput\n",
    "writeOutput(recItems_test, 'BCQ-QLearning_v1.csv', userIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd948d1-19fc-4c28-a2f4-c52cd6c85461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2222dd-7e76-46d3-a6af-24d52b4a5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03fcaf-6713-486d-ab61-0dd8c900db2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
